# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file exp/bnf_extractor/configs/network.xconfig --config-dir exp/bnf_extractor/configs/
# It contains the entire neural network, but with those
# components that would normally require fixed vectors/matrices
# read from disk, replaced with random initialization
# (this applies to the LDA-like transform and the
# presoftmax-prior-scale, if applicable).  This file
# is used only to work out the left-context and right-context
# of the network.

input-node name=input dim=30
component name=lda type=FixedAffineComponent input-dim=150 output-dim=150
component-node name=lda component=lda input=Append(Offset(input, -2), Offset(input, -1), input, Offset(input, 1), Offset(input, 2))
component name=tdnn1.affine type=NaturalGradientAffineComponent input-dim=150 output-dim=850  max-change=0.75
component-node name=tdnn1.affine component=tdnn1.affine input=lda
component name=tdnn1.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn1.relu component=tdnn1.relu input=tdnn1.affine
component name=tdnn1.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn1.batchnorm component=tdnn1.batchnorm input=tdnn1.relu
component name=tdnn2.affine type=NaturalGradientAffineComponent input-dim=2550 output-dim=850  max-change=0.75
component-node name=tdnn2.affine component=tdnn2.affine input=Append(Offset(tdnn1.batchnorm, -1), tdnn1.batchnorm, Offset(tdnn1.batchnorm, 2))
component name=tdnn2.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn2.relu component=tdnn2.relu input=tdnn2.affine
component name=tdnn2.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn2.batchnorm component=tdnn2.batchnorm input=tdnn2.relu
component name=tdnn3.affine type=NaturalGradientAffineComponent input-dim=2550 output-dim=850  max-change=0.75
component-node name=tdnn3.affine component=tdnn3.affine input=Append(Offset(tdnn2.batchnorm, -3), tdnn2.batchnorm, Offset(tdnn2.batchnorm, 3))
component name=tdnn3.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn3.relu component=tdnn3.relu input=tdnn3.affine
component name=tdnn3.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn3.batchnorm component=tdnn3.batchnorm input=tdnn3.relu
component name=tdnn4.affine type=NaturalGradientAffineComponent input-dim=2550 output-dim=850  max-change=0.75
component-node name=tdnn4.affine component=tdnn4.affine input=Append(Offset(tdnn3.batchnorm, -7), tdnn3.batchnorm, Offset(tdnn3.batchnorm, 2))
component name=tdnn4.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn4.relu component=tdnn4.relu input=tdnn4.affine
component name=tdnn4.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn4.batchnorm component=tdnn4.batchnorm input=tdnn4.relu
component name=tdnn5.affine type=NaturalGradientAffineComponent input-dim=2550 output-dim=850  max-change=0.75
component-node name=tdnn5.affine component=tdnn5.affine input=Append(Offset(tdnn4.batchnorm, -3), tdnn4.batchnorm, Offset(tdnn4.batchnorm, 3))
component name=tdnn5.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn5.relu component=tdnn5.relu input=tdnn5.affine
component name=tdnn5.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn5.batchnorm component=tdnn5.batchnorm input=tdnn5.relu
component name=bnf type=NaturalGradientAffineComponent input-dim=850 output-dim=50  param-stddev=0.03429971702850177 bias-stddev=1.0 bias-mean=0.0 max-change=0.75 l2-regularize=0.0
component-node name=bnf component=bnf input=tdnn5.batchnorm
component name=tdnn6.affine type=NaturalGradientAffineComponent input-dim=50 output-dim=850  max-change=0.75
component-node name=tdnn6.affine component=tdnn6.affine input=bnf
component name=tdnn6.relu type=RectifiedLinearComponent dim=850 self-repair-scale=1e-05
component-node name=tdnn6.relu component=tdnn6.relu input=tdnn6.affine
component name=tdnn6.batchnorm type=BatchNormComponent dim=850 target-rms=1.0
component-node name=tdnn6.batchnorm component=tdnn6.batchnorm input=tdnn6.relu
component name=output.affine type=NaturalGradientAffineComponent input-dim=850 output-dim=7936  max-change=1.5 param-stddev=0.0 bias-stddev=0.0
component-node name=output.affine component=output.affine input=tdnn6.batchnorm
component name=output.log-softmax type=LogSoftmaxComponent dim=7936
component-node name=output.log-softmax component=output.log-softmax input=output.affine
output-node name=output input=output.log-softmax objective=linear
